{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a chat conversation\n",
    "The Gemini SDK lets you collect multiple rounds of questions and responses, allowing users to step incrementally toward answers or get help with multipart problems. This SDK feature provides an interface to keep track of conversations history, but behind the scenes uses the same generateContent method to create the response.\n",
    "\n",
    "The following code example shows a basic chat implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's wonderful!  What breeds are they?  Do they get along well?  Tell me more about your furry friends!\n",
      "\n",
      "If you have two dogs, and each dog has four paws, then there are eight paws in your house.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the load_dotenv function from the dotenv library to load environment variables from a .env file.\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Import the os module to interact with the operating system and retrieve environment variables.\n",
    "import os\n",
    "\n",
    "# Import the google.generativeai library as genai to access Google's generative AI capabilities.\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Load environment variables from a .env file into the program's environment.\n",
    "load_dotenv()\n",
    "\n",
    "# Configure the generative AI library with the API key stored in the environment variable \"GEMINI_API_KEY\".\n",
    "# This key is retrieved using os.getenv() to keep sensitive data secure.\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "# Initialize a generative AI model with the specific version \"gemini-1.5-flash\".\n",
    "# This specifies the AI model to be used for generating responses.\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "# Start a chat session with the AI model, providing an initial history to simulate the beginning of a conversation.\n",
    "# The `history` parameter contains a list of messages, including a user greeting and the model's response.\n",
    "chat = model.start_chat(\n",
    "    history=[\n",
    "        {\"role\": \"user\", \"parts\": \"Hello\"},  # The user starts the conversation with \"Hello\".\n",
    "        {\"role\": \"model\", \"parts\": \"Great to meet you. What would you like to know?\"},  # The AI model responds.\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Send a new message to the AI model in the chat session.\n",
    "# The user tells the model, \"I have 2 dogs in my house.\"\n",
    "response = chat.send_message(\"I have 2 dogs in my house.\")\n",
    "\n",
    "# Print the response generated by the AI model to the message about having 2 dogs.\n",
    "print(response.text)\n",
    "\n",
    "# Send another message to the AI model, asking, \"How many paws are in my house?\"\n",
    "response2 = chat.send_message(\"How many paws are in my house?\")\n",
    "\n",
    "# Print the AI model's response to the question about the number of paws.\n",
    "print(response2.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a chat with streaming conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's lovely!  Do you have any questions about them, or would you like to tell me more about them?  Perhaps their breeds, names, or their personalities?\n",
      "Assuming each of your two dogs has four paws, there are eight paws in your house.\n",
      "[parts {\n",
      "  text: \"Hello\"\n",
      "}\n",
      "role: \"user\"\n",
      ", parts {\n",
      "  text: \"Great to meet you. What would you like to know?\"\n",
      "}\n",
      "role: \"model\"\n",
      ", parts {\n",
      "  text: \"I have 2 dogs in my house.\"\n",
      "}\n",
      "role: \"user\"\n",
      ", parts {\n",
      "  text: \"That\\'s lovely!  Do you have any questions about them, or would you like to tell me more about them?  Perhaps their breeds, names, or their personalities?\\n\"\n",
      "}\n",
      "role: \"model\"\n",
      ", parts {\n",
      "  text: \"How many paws are in my house?\"\n",
      "}\n",
      "role: \"user\"\n",
      ", parts {\n",
      "  text: \"Assuming each of your two dogs has four paws, there are eight paws in your house.\\n\"\n",
      "}\n",
      "role: \"model\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "chat = model.start_chat(\n",
    "    history=[\n",
    "        {\"role\": \"user\", \"parts\": \"Hello\"},\n",
    "        {\"role\": \"model\", \"parts\": \"Great to meet you. What would you like to know?\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = chat.send_message(\"I have 2 dogs in my house.\", stream=True)\n",
    "for chunk in response:\n",
    "    print(chunk.text, end=\"\")\n",
    "\n",
    "response2 = chat.send_message(\"How many paws are in my house?\", stream=True)\n",
    "for chunk in response2:\n",
    "    print(chunk.text, end=\"\")\n",
    "\n",
    "print(chat.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
