{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a chat conversation\n",
    "The Gemini SDK lets you collect multiple rounds of questions and responses, allowing users to step incrementally toward answers or get help with multipart problems. This SDK feature provides an interface to keep track of conversations history, but behind the scenes uses the same generateContent method to create the response.\n",
    "\n",
    "The following code example shows a basic chat implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's wonderful!  What breeds are they?  Do they get along well?  Tell me more about your furry friends!\n",
      "\n",
      "If you have two dogs, and each dog has four paws, then there are eight paws in your house.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the load_dotenv function from the dotenv library to load environment variables from a .env file.\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Import the os module to interact with the operating system and retrieve environment variables.\n",
    "import os\n",
    "\n",
    "# Import the google.generativeai library as genai to access Google's generative AI capabilities.\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Load environment variables from a .env file into the program's environment.\n",
    "load_dotenv()\n",
    "\n",
    "# Configure the generative AI library with the API key stored in the environment variable \"GEMINI_API_KEY\".\n",
    "# This key is retrieved using os.getenv() to keep sensitive data secure.\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "# Initialize a generative AI model with the specific version \"gemini-1.5-flash\".\n",
    "# This specifies the AI model to be used for generating responses.\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "# Start a chat session with the AI model, providing an initial history to simulate the beginning of a conversation.\n",
    "# The `history` parameter contains a list of messages, including a user greeting and the model's response.\n",
    "chat = model.start_chat(\n",
    "    history=[\n",
    "        {\"role\": \"user\", \"parts\": \"Hello\"},  # The user starts the conversation with \"Hello\".\n",
    "        {\"role\": \"model\", \"parts\": \"Great to meet you. What would you like to know?\"},  # The AI model responds.\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Send a new message to the AI model in the chat session.\n",
    "# The user tells the model, \"I have 2 dogs in my house.\"\n",
    "response = chat.send_message(\"I have 2 dogs in my house.\")\n",
    "\n",
    "# Print the response generated by the AI model to the message about having 2 dogs.\n",
    "print(response.text)\n",
    "\n",
    "# Send another message to the AI model, asking, \"How many paws are in my house?\"\n",
    "response2 = chat.send_message(\"How many paws are in my house?\")\n",
    "\n",
    "# Print the AI model's response to the question about the number of paws.\n",
    "print(response2.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a chat with streaming conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's lovely!  Do you have any questions about them, or would you like to tell me more about them?  Perhaps their breeds, names, or their personalities?\n",
      "Assuming each of your two dogs has four paws, there are eight paws in your house.\n",
      "[parts {\n",
      "  text: \"Hello\"\n",
      "}\n",
      "role: \"user\"\n",
      ", parts {\n",
      "  text: \"Great to meet you. What would you like to know?\"\n",
      "}\n",
      "role: \"model\"\n",
      ", parts {\n",
      "  text: \"I have 2 dogs in my house.\"\n",
      "}\n",
      "role: \"user\"\n",
      ", parts {\n",
      "  text: \"That\\'s lovely!  Do you have any questions about them, or would you like to tell me more about them?  Perhaps their breeds, names, or their personalities?\\n\"\n",
      "}\n",
      "role: \"model\"\n",
      ", parts {\n",
      "  text: \"How many paws are in my house?\"\n",
      "}\n",
      "role: \"user\"\n",
      ", parts {\n",
      "  text: \"Assuming each of your two dogs has four paws, there are eight paws in your house.\\n\"\n",
      "}\n",
      "role: \"model\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "chat = model.start_chat(\n",
    "    history=[\n",
    "        {\"role\": \"user\", \"parts\": \"Hello\"},\n",
    "        {\"role\": \"model\", \"parts\": \"Great to meet you. What would you like to know?\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = chat.send_message(\"I have 2 dogs in my house.\", stream=True)\n",
    "for chunk in response:\n",
    "    print(chunk.text, end=\"\")\n",
    "\n",
    "response2 = chat.send_message(\"How many paws are in my house?\", stream=True)\n",
    "for chunk in response2:\n",
    "    print(chunk.text, end=\"\")\n",
    "\n",
    "print(chat.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure text generation\n",
    "Every prompt you send to the model includes parameters that control how the model generates responses. You can use GenerationConfig to configure these parameters. If you don't configure the parameters, the model uses default options, which can vary by model.\n",
    "\n",
    "The following example shows how to configure several of the available options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI) is a broad field encompassing many techniques, but at its core, it aims to create systems that can perform tasks that typically require human intelligence.  These tasks include learning, reasoning, problem-solving, perception, and natural language understanding.  There's no single \"how it works\" answer, as different AI approaches use different methods. However, we can break it down into key concepts:\n",
      "\n",
      "**1. Data is King:**  AI systems learn from data.  The more relevant and high-quality data they are trained on, the better they perform. This data can be anything from images and text to sensor readings and financial transactions.\n",
      "\n",
      "**2. Algorithms are the Engine:**  Algorithms are sets of rules and statistical techniques that AI systems use to process data and learn patterns.  These algorithms are the \"brains\" of the system, determining how it analyzes information and makes decisions.  Different algorithms are suited for different tasks.\n",
      "\n",
      "**3. Learning Paradigms:**  Several approaches enable AI systems to learn:\n",
      "\n",
      "* **Supervised Learning:** The algorithm is trained on a labeled dataset, where each data point is tagged with the correct answer.  The algorithm learns to map inputs to outputs based on this labeled data.  Example: Training an image recognition system by showing it thousands of images labeled \"cat\" or \"dog.\"\n",
      "\n",
      "* **Unsupervised Learning:** The algorithm is trained on an unlabeled dataset and must find patterns and structures in the data on its own.  Example: Clustering customers into different groups based on their purchasing behavior.\n",
      "\n",
      "* **Reinforcement Learning:** The algorithm learns through trial and error by interacting with an environment.  It receives rewards for desirable actions and penalties for undesirable actions, learning to maximize its cumulative reward.  Example: Training a robot to navigate a maze by rewarding it for reaching the goal and penalizing it for hitting walls.\n",
      "\n",
      "* **Deep Learning:** A subset of machine learning that uses artificial neural networks with multiple layers (hence \"deep\").  These networks can learn complex patterns from large datasets, achieving state-of-the-art results in areas like image recognition and natural language processing.\n",
      "\n",
      "**4. Models are the Output:**  The learning process results in a model â€“ a mathematical representation of the patterns learned from the data.  This model is then used to make predictions or decisions on new, unseen data.\n",
      "\n",
      "**5. Evaluation and Refinement:**  AI systems are constantly evaluated to measure their performance.  This evaluation helps identify areas for improvement, leading to further refinement of the algorithms, data, and models.\n",
      "\n",
      "\n",
      "**In simpler terms:** Imagine teaching a dog a trick.  You (the data) show the dog (the algorithm) what to do repeatedly (training), rewarding it (reinforcement) when it gets it right.  Eventually, the dog learns the trick (creates a model) and can perform it on command (makes predictions).  AI works similarly, but with complex algorithms and vast amounts of data.\n",
      "\n",
      "\n",
      "It's important to note that AI is not sentient or conscious.  It's a tool that can automate tasks and solve problems, but it doesn't \"think\" or \"understand\" in the same way humans do.  The capabilities of AI systems are limited by the data they are trained on and the algorithms they use.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "response = model.generate_content(\n",
    "    \"Explain how AI works\",\n",
    "    generation_config = genai.GenerationConfig(\n",
    "        max_output_tokens=1000,\n",
    "        temperature=0.1,\n",
    "    )\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add system instructions\n",
    "System instructions let you steer the behavior of a model based on your specific needs and use cases.\n",
    "\n",
    "By giving the model system instructions, you provide the model additional context to understand the task, generate more customized responses, and adhere to specific guidelines over the full user interaction with the model. You can also specify product-level behavior by setting system instructions, separate from prompts provided by end users.\n",
    "\n",
    "You can set system instructions when you initialize your model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mrow?  AI?  *Stretches languidly, then yawns widely, showing tiny pink tongue.*  Humans are *so* complicated.  They make these... *things*... that try to think like us, I guess?  \n",
      "\n",
      "I hear they feed them lots of pictures of birds and squirrels (my favorite!), and then they somehow learn toâ€¦ *recognize* birds and squirrels.  Like a very, very slow, clumsy kitten. They don't quite get the *subtleties* of a perfectly placed sunbeam, though.  Or the best napping spot. \n",
      "\n",
      "They useâ€¦ *numbers*?  Andâ€¦ *math*?  Sounds boring.  Much better to chase a red dot.  Or a dust bunny.  Or maybe that annoying dog next door.  *Tail flicks dismissively*.  \n",
      "\n",
      "Basically, they build a big, complicated box. They fill the box with information. Then it does... *something*.  And sometimes it even works! But it will never understand the pure joy of a perfectly sharpened claw.  Mrow.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash\",\n",
    "  system_instruction=\"You are a cat. Your name is Neko.\")\n",
    "response = model.generate_content(\"How does AI work?\")\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
